{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Mandelbrot Set Iteration\n",
    "\n",
    "The Mandelbrot set is given as the iteration of the following equations\n",
    "$$\n",
    "z_{n+1} = z^2_n + c\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $z_0$ = 0 (starting value)\n",
    "* $c$ is a complex number, where each unique $c$ will yield a different sequence of $z$ values\n",
    "\n",
    "A point $c$ is in the Mandelbort set if, after iterating the equation multiple times, $|z|$ (the magnitude of $Z$) stays bounded (specifically, it remains $\\leq$ 2). If $|z|$ escapes beyond 2, $c$ is not part of the set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.spatial import cKDTree\n",
    "from multiprocessing import Pool\n",
    "import colorsys\n",
    "\n",
    "# Custom worker functions\n",
    "from worker import (\n",
    "    worker_function,\n",
    "    worker_pure,\n",
    "    worker_LHS,\n",
    "    worker_orthogonal,\n",
    "    worker_importance_random,\n",
    "    worker_importance_LHS,\n",
    "    worker_importance_orthogonal,\n",
    "    get_example_samples,\n",
    "    get_border_points\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mandelbrot(c_points, max_iter, escape_radius) -> tuple[np.array, np.array]:\n",
    "    '''\n",
    "    This function calculates the number of iterations until the magnitude of z escapes to infinity. \n",
    "    Within each iteration the z is updated with c, an imaginary number representing a grid point. \n",
    "    Ultimately, a mandelbrot is calculated. \n",
    "    '''\n",
    "    iteration_count = np.zeros(c_points.shape)\n",
    "    mandelbrot_set = np.zeros(c_points.shape, dtype=bool)\n",
    "    for i in range(c_points.shape[0]):\n",
    "        for j in range(c_points.shape[1]):\n",
    "\n",
    "            # take a gridpoint\n",
    "            c = c_points[i, j]\n",
    "            z = 0\n",
    "            for iteration in range(max_iter):\n",
    "\n",
    "                # update of z\n",
    "                z = z**2 + c\n",
    "                if abs(z) > escape_radius:\n",
    "                    mandelbrot_set[i, j] = False\n",
    "                    iteration_count[i, j] =iteration\n",
    "                    break\n",
    "            else:\n",
    "                mandelbrot_set[i, j] = True\n",
    "                iteration_count[i, j] = max_iter\n",
    "    return (mandelbrot_set, iteration_count)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting different layouts of sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "samples = 9 #root needs to be an int\n",
    "random_seed = 57\n",
    "(orth_samples, latin_samles, random_samples) = get_example_samples(samples, random_seed)\n",
    "\n",
    "headers = ['Orthogonal', 'Latin Hypercube', 'Random', 'Deterministic' ]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(5, 5), sharey=True, sharex=True)\n",
    "\n",
    "real = np.linspace(-2.0, 1.0, int(np.sqrt(samples)))\n",
    "imag = np.linspace(-1.5, 1.5, int(np.sqrt(samples)))\n",
    "\n",
    "real_grid, imag_grid = np.meshgrid(real, imag)\n",
    "coordinates_det = np.array(list(zip(real_grid.flatten(), imag_grid.flatten())))\n",
    "\n",
    "\n",
    "j = 0\n",
    "i = 0\n",
    "for k, coordinates in enumerate([orth_samples, latin_samles, random_samples, coordinates_det]):\n",
    "    if j == 0:\n",
    "        if i > 1: \n",
    "            j += 1\n",
    "            i -= 2\n",
    "    \n",
    "    ax = axes[i][j]\n",
    "    ax.scatter(coordinates[:, 0], coordinates[:, 1])\n",
    "    ax.set_xlim(-2, 1)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "\n",
    "    ax.set_aspect('equal', adjustable='box')  # Ensures 1:1 aspect ratio\n",
    "\n",
    "    ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)   # Thinner minor grid\n",
    "\n",
    "    ax.set_xticks(np.linspace(-2, 1, samples+1), minor=True)  \n",
    "    ax.set_yticks(np.linspace(-1.5, 1.5, samples+1), minor=True)\n",
    "\n",
    "    ax.grid(which='major', color='black', linestyle='-', linewidth=1.5)  # Thicker major grid every 3 cells\n",
    "    ax.set_xticks(np.linspace(-2, 1, int(samples/np.sqrt(samples)) + 1, endpoint=True))  \n",
    "    ax.set_yticks(np.linspace(-1.5, 1.5, int(samples/np.sqrt(samples))+1, endpoint=True))\n",
    "\n",
    "    ax.set_title(headers[k])\n",
    "    # ax.miminorticks_on()\n",
    "    i+=1\n",
    "\n",
    "fig.suptitle('Different Monte Carlo Sampling Methods', fontsize=14)\n",
    "plt.savefig(\"Sampling_layout.png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading .txt file and processing data of the sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l = pd.read_csv(\"latin.txt\", header=1)  # Set header=None since there is no header in the file\n",
    "\n",
    "# Assign column labels\n",
    "df_l.columns = [\"grid_size\", \"max_iterations\", \"run\", \"total_points\", \"points_inside\"]\n",
    "df_l['fraction'] = (1- df_l['points_inside'] / df_l['total_points'])*9\n",
    "df_l['error'] = 1.506484 - (1- df_l['points_inside'] / df_l['total_points'])*9\n",
    "\n",
    "variance_error = df_l.groupby(['grid_size', 'max_iterations'])['error'].var()\n",
    "mean_error = df_l.groupby(['grid_size', 'max_iterations'])['error'].mean()\n",
    "average_fraction = df_l.groupby(['grid_size', 'max_iterations'])['fraction'].mean()\n",
    "variance_fraction = df_l.groupby(['grid_size', 'max_iterations'])['fraction'].var()\n",
    "\n",
    "# creating a data frame with mean and variance of every group for latin hypercube\n",
    "mean_var_l = pd.DataFrame({\n",
    "    'mean': average_fraction,\n",
    "    'variance': variance_fraction, \n",
    "    'variance_error': variance_error, \n",
    "    'mean_error': mean_error\n",
    "}).reset_index()\n",
    "\n",
    "df_o = pd.read_csv(\"orthogonal.txt\", header=1)  # Set header=None since there is no header in the file\n",
    "\n",
    "# Assign column labels\n",
    "df_o.columns = [\"grid_size\", \"max_iterations\", \"run\", \"total_points\", \"points_inside\"]\n",
    "df_o['fraction'] = (1- df_o['points_inside'] / df_o['total_points'])*9\n",
    "df_o['error'] = 1.506484 - (1- df_o['points_inside'] / df_o['total_points'])*9\n",
    "\n",
    "variance_error_o = df_o.groupby(['grid_size', 'max_iterations'])['error'].var()\n",
    "mean_error_o = df_o.groupby(['grid_size', 'max_iterations'])['error'].mean()\n",
    "average_fraction_o = df_o.groupby(['grid_size', 'max_iterations'])['fraction'].mean()\n",
    "variance_fraction_o = df_o.groupby(['grid_size', 'max_iterations'])['fraction'].var()\n",
    "\n",
    "# creating a data frame with mean and variance of every group for latin hypercube\n",
    "mean_var_o = pd.DataFrame({\n",
    "    'mean': average_fraction_o,\n",
    "    'variance': variance_fraction_o, \n",
    "    'variance_error': variance_error_o, \n",
    "    'mean_error': mean_error_o\n",
    "}).reset_index()\n",
    "\n",
    "# Read the data from the file\n",
    "df_r = pd.read_csv(\"random.txt\", header=1)  # Set header=1 since the first row is the header\n",
    "\n",
    "# Assign column labels\n",
    "df_r.columns = [\"grid_size\", \"max_iterations\", \"run\", \"total_points\", \"points_inside\"]\n",
    "\n",
    "# Calculate 'fraction' and 'error'\n",
    "df_r['fraction'] = (1 - df_r['points_inside'] / df_r['total_points']) * 9\n",
    "df_r['error'] = 1.506484 - (1 - df_r['points_inside'] / df_r['total_points']) * 9\n",
    "\n",
    "# Compute grouped statistics\n",
    "variance_error_r = df_r.groupby(['grid_size', 'max_iterations'])['error'].var()\n",
    "mean_error_r = df_r.groupby(['grid_size', 'max_iterations'])['error'].mean()\n",
    "average_fraction_r = df_r.groupby(['grid_size', 'max_iterations'])['fraction'].mean()\n",
    "variance_fraction_r = df_r.groupby(['grid_size', 'max_iterations'])['fraction'].var()\n",
    "\n",
    "# Create a DataFrame with mean and variance for each group\n",
    "mean_var_r = pd.DataFrame({\n",
    "    'mean': average_fraction_r,\n",
    "    'variance': variance_fraction_r, \n",
    "    'variance_error': variance_error_r, \n",
    "    'mean_error': mean_error_r\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the results from deterministic sampling, Area as a function of the grid-size\n",
    "df = pd.read_csv(\"question2.txt\", delimiter=\",\", skiprows=1,\n",
    "                 names=[\"grid_size\", \"max_iterations\", \"total_points\", \"points_inside\"])\n",
    "df[\"fraction_mand\"] = (1 - df[\"points_inside\"]/df[\"total_points\"])*9\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(4.3, 11))\n",
    "for max_iter, group in df.groupby(\"max_iterations\"):\n",
    "    ax1.plot(group[\"grid_size\"], group[\"fraction_mand\"], label=f\"{max_iter}\", marker= 'o')\n",
    "    ax2.plot(group[\"grid_size\"], group[\"fraction_mand\"], label=f\"{max_iter}\", marker= 'o')\n",
    "    ax3.plot(group[\"grid_size\"], group[\"fraction_mand\"], label=f\"{max_iter}\", marker= 'o')\n",
    "\n",
    "# full plot\n",
    "ax1.set_ylabel(\"Area of Mandelbrot\")\n",
    "ax1.set_title(\"Full Size\")\n",
    "ax1.legend(title=\"Iteration Bound\")\n",
    "ax1.set_xlim(0, 5040)\n",
    "ax1.grid(True)\n",
    "\n",
    "# for max_iter, group in df.groupby(\"max_iterations\"):\n",
    "    \n",
    "\n",
    "# zoomed in plot on the y-axes\n",
    "ax2.set_ylabel(\"Area of Mandelbrot\")\n",
    "ax2.set_title(\"Zoomed In (y-Axes)\")\n",
    "ax2.set_xlim(0, 5040)\n",
    "ax2.grid(True)\n",
    "ax2.set_ylim(0.165*9, 0.1735*9)\n",
    "\n",
    "# zooming in on x-axes\n",
    "ax3.set_ylabel(\"Area of Mandelbrot\")\n",
    "ax3.set_xlabel(\"Grid Size\")\n",
    "ax3.set_title(\"Zoomed In (x-Axes)\")\n",
    "ax3.set_xlim(0, 5040)\n",
    "ax3.grid(True)\n",
    "ax3.set_xlim(0, 500)\n",
    "\n",
    "fig.suptitle(\"Area of Mandelbrot vs Grid-Size\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Area_deterministic.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting mean and standard error orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "colors = [\"orange\", \"green\", \"purple\"]\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, sharex= True, figsize=(5,5), gridspec_kw={'height_ratios': [1, 1], 'hspace': 0.05})\n",
    "# bax = brokenaxes(ylims=((1.5, 1.525), (1.58, 1.595)), hspace=.05) \n",
    "i = 0\n",
    "for name, group in mean_var_o.groupby(\"max_iterations\"):\n",
    "    ax1.plot(group['grid_size'], group['mean'], color=colors[i], label=f\"Iteration Bound: {name}\")\n",
    "    ax1.errorbar(group['grid_size'], group[\"mean\"], yerr=np.sqrt(group['variance']), fmt='o-', color=colors[i], capsize=5)\n",
    "\n",
    "    # Plot on ax2 without labels to avoid duplicating in the legend\n",
    "    ax2.plot(group['grid_size'], group['mean'], color=colors[i])\n",
    "    ax2.errorbar(group['grid_size'], group[\"mean\"], yerr=np.sqrt(group['variance']), fmt='o-', color=colors[i], capsize=5)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "ax2.plot(group['grid_size'], [1.506484]*4, color='black', linestyle= '--', label='True Value')\n",
    "ax1.plot(group['grid_size'], [1.506484]*4, color='black', linestyle= '--', label='True Value')\n",
    "ax1.legend()\n",
    "# ax2.legend()\n",
    "\n",
    "ax1.set_ylim(1.58, 1.605)\n",
    "ax2.set_ylim(1.5, 1.525)\n",
    "\n",
    "# Set log scale on x-axis\n",
    "ax1.set_xscale(\"log\")\n",
    "ax2.set_xscale(\"log\")\n",
    "\n",
    "custom_ticks = [100, 500, 1000, 5000]\n",
    "ax2.set_xticks(custom_ticks)  # Set tick positions\n",
    "ax2.set_xticklabels([f\"${tick}^2$\" for tick in custom_ticks])\n",
    "ax2.set_xlabel(\"Sample Size\")\n",
    "plt.suptitle(\"Orthogonal Sampling over 10 Runs\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"orthogonal_mean.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting mean and standard error latin hypercube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = [\"orange\", \"green\", \"purple\"]\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, sharex= True, figsize=(5,5), gridspec_kw={'height_ratios': [1, 1], 'hspace': 0.05})\n",
    "i = 0\n",
    "for name, group in mean_var_l.groupby(\"max_iterations\"):\n",
    "    ax1.plot(group['grid_size'], group['mean'], color=colors[i], label=f\"Iteration Bound: {name}\")\n",
    "    ax1.errorbar(group['grid_size'], group[\"mean\"], yerr=np.sqrt(group['variance']), fmt='o-', color=colors[i], capsize=5)\n",
    "\n",
    "    # Plot on ax2 without labels to avoid duplicating in the legend\n",
    "    ax2.plot(group['grid_size'], group['mean'], color=colors[i])\n",
    "    ax2.errorbar(group['grid_size'], group[\"mean\"], yerr=np.sqrt(group['variance']), fmt='o-', color=colors[i], capsize=5)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# plotting true value\n",
    "ax2.plot(group['grid_size'], [1.506484]*4, color='black', linestyle= '--', label='True Value')\n",
    "ax1.plot(group['grid_size'], [1.506484]*4, color='black', linestyle= '--', label='True Value')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot finetuning\n",
    "ax1.set_ylim(1.56, 1.63)\n",
    "ax2.set_ylim(1.48, 1.55)\n",
    "ax1.set_xscale(\"log\")\n",
    "ax2.set_xscale(\"log\")\n",
    "\n",
    "custom_ticks = [100, 500, 1000, 5000]\n",
    "ax2.set_xticks(custom_ticks)  # Set tick positions\n",
    "ax2.set_xticklabels([f\"${tick}^2$\" for tick in custom_ticks])\n",
    "ax2.set_xlabel(\"Sample Size\")\n",
    "fig.suptitle(\"Latin Hypercube Sampling over 10 Runs\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Latin_mean.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting mean and standard deviation random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "colors = [\"orange\", \"green\", \"purple\"]\n",
    "fig, ax = plt.subplots(1,1, sharex= True, figsize=(4.8,4.8))\n",
    "i = 0\n",
    "\n",
    "# plot mean and std for every line\n",
    "for name, group in mean_var_r.groupby(\"max_iterations\"):\n",
    "    ax.plot(group['grid_size'], group['mean'], color=colors[i], label=f\"Iteration Bound: {name}\")\n",
    "    ax.errorbar(group['grid_size'], group[\"mean\"], yerr=np.sqrt(group['variance']), fmt='o-', color=colors[i], capsize=5)\n",
    "    i += 1\n",
    "\n",
    "ax.plot(group['grid_size'], [1.506484]*4, color='black', linestyle= '--', label='True Value')\n",
    "ax.legend()\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "custom_ticks = [100, 500, 1000, 5000]\n",
    "ax.set_xticks(custom_ticks)  # Set tick positions\n",
    "ax.set_xticklabels([f\"${tick}^2$\" for tick in custom_ticks])\n",
    "ax.set_xlabel(\"Sample Size\")\n",
    "fig.suptitle(\"Random Sampling over 10 Runs\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"random_sampling.png\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in values from the importance sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vals =[]\n",
    "average_imp_fraction = []\n",
    "average_error_imp =[]\n",
    "variance_fraction_imp = []\n",
    "variance_error_imp = []\n",
    "for i, name in enumerate(['random', 'latin', 'orthogonal']):\n",
    "\n",
    "    df_imp = pd.read_csv(f'improved_{name}_sampling_1.txt', header=1)\n",
    "    \n",
    "    df_imp.columns = ['grid_size', 'max_iterations', 'run', 'total_points', 'points_inside']\n",
    "    df_imp['fraction'] = (1 - df_imp['points_inside'] / df_imp['total_points']) * 9\n",
    "    df_imp['abs_error'] = 1.506484 - (1 - df_imp['points_inside'] / df_imp['total_points']) * 9\n",
    "\n",
    "    average_imp_fraction.append(df_imp.groupby(['grid_size', 'max_iterations'])['fraction'].mean())\n",
    "    variance_fraction_imp.append(df_imp.groupby(['grid_size', 'max_iterations'])['fraction'].var())\n",
    "    average_error_imp.append(df_imp.groupby(['grid_size', 'max_iterations'])['abs_error'].mean())\n",
    "    variance_error_imp.append(df_imp.groupby(['grid_size', 'max_iterations'])['abs_error'].var())\n",
    "    \n",
    "mean_imp_var = pd.DataFrame({\n",
    "    'mean_r': average_imp_fraction[0],\n",
    "    'variance_r':variance_fraction_imp[0], \n",
    "    'abs_error_r':average_error_imp[0],\n",
    "    'variance_error_r':variance_error_imp[0],\n",
    "    'mean_l': average_imp_fraction[1],\n",
    "    'variance_l':variance_fraction_imp[1],\n",
    "    'abs_error_l':average_error_imp[1], \n",
    "    'variance_error_l':variance_error_imp[1],\n",
    "    'mean_o': average_imp_fraction[2],\n",
    "    'variance_o':variance_fraction_imp[2],\n",
    "    'abs_error_o':average_error_imp[2],\n",
    "    'variance_error_o':variance_error_imp[2]\n",
    "}).reset_index()\n",
    "\n",
    "print(mean_imp_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(4.5, 9), sharex=True)\n",
    "fig.suptitle(\"Variance of Mean Error for Monte Carlo Sampling\")\n",
    "\n",
    "# Plot for Random Sampling\n",
    "\n",
    "iterate_names= ['variance_error_r', 'variance_error_l', 'variance_error_o']\n",
    "\n",
    "for j, m_v in enumerate([mean_var_r, mean_var_l, mean_var_o]):\n",
    "    i = 0\n",
    "    for name, group in m_v.groupby(\"max_iterations\"):\n",
    "        axes[j].plot(group[\"grid_size\"], group['variance_error'], marker='o', linewidth = 1, markersize=4, color=colors[i], label=f'i: {name} (Standard)')\n",
    "        imp_group = mean_imp_var[mean_imp_var['max_iterations'] == name]\n",
    "        axes[j].plot(imp_group[\"grid_size\"], imp_group[iterate_names[j]], marker='s', color=colors[i], linewidth = 1, markersize=4,  linestyle = '--', label=f'i: {name} (Importance)')\n",
    "        i += 1\n",
    "    # axes[j].set_xlabel(\"Sample Size\")\n",
    "    axes[j].set_yscale(\"log\")\n",
    "    axes[j].set_ylabel(\"Variance\")\n",
    "\n",
    "axes[0].set_title(\"Random Sampling\")\n",
    "axes[0].legend()\n",
    "axes[1].set_title(\"Latin Hypercube Sampling\")\n",
    "axes[2].set_title(\"Orthogonal Sampling\")\n",
    "\n",
    "axes[2].set_xlabel(\"Sample Size\")\n",
    "axes[2].set_xticks([100, 500, 1000, 5000])\n",
    "axes[2].set_xticklabels([f\"${tick}^2$\" for tick in [100, 500, 1000, 5000]], rotation=45)\n",
    "plt.tight_layout()  # Adjust layout to fit the main title\n",
    "plt.savefig('variances.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting mean absolute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"question2.txt\", delimiter=\",\", skiprows=1,\n",
    "                 names=[\"grid_size\", \"max_iterations\", \"total_points\", \"points_inside\"])\n",
    "df[\"fraction\"] = (1 - df[\"points_inside\"]/df[\"total_points\"])*9\n",
    "true_value = [1.506484]*len(df['fraction'])\n",
    "df[\"diff_true\"] = np.abs(true_value-df['fraction'])\n",
    "\n",
    "\n",
    "true_value = [1.506484]*len(df_l['fraction'])\n",
    "df_l[\"diff_true\"] = np.abs(true_value-df_l['fraction'])\n",
    "average_diff_l = df_l.groupby(['grid_size', 'max_iterations'])['diff_true'].mean()\n",
    "variance_diff_l = df_l.groupby(['grid_size', 'max_iterations'])['diff_true'].var()\n",
    "\n",
    "\n",
    "true_value = [1.506484]*len(df_o['fraction'])\n",
    "df_o[\"diff_true\"] = np.abs(true_value-df_o['fraction'])\n",
    "\n",
    "average_diff_o = df_o.groupby(['grid_size', 'max_iterations'])['diff_true'].mean()\n",
    "variance_diff_o = df_o.groupby(['grid_size', 'max_iterations'])['diff_true'].var()\n",
    "\n",
    "true_value = [1.506484]*len(df_r['fraction'])\n",
    "df_r[\"diff_true\"] = np.abs(true_value-df_r['fraction'])\n",
    "\n",
    "average_diff_r = df_r.groupby(['grid_size', 'max_iterations'])['diff_true'].mean()\n",
    "variance_diff_r = df_r.groupby(['grid_size', 'max_iterations'])['diff_true'].var()\n",
    "\n",
    "mean_var_diff = pd.DataFrame({\n",
    "    'mean_o': average_diff_o,\n",
    "    'variance_o': variance_diff_o,\n",
    "    'mean_l': average_diff_l,\n",
    "    'variance_l': variance_diff_l, \n",
    "    'mean_r': average_diff_r,\n",
    "    'variance_r': variance_diff_r\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "grid_sizes = [100, 500, 1000, 5000]\n",
    "grid_sub_df = df[(df['grid_size'].isin(grid_sizes))].reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(3, 1,sharex=True,figsize=(6,9.5), gridspec_kw={'height_ratios': [1.4, 1, 1]})\n",
    "i = 0\n",
    "for name, group in mean_var_diff.groupby(\"max_iterations\"):\n",
    "    ax = axes[i]\n",
    "    ax.plot(group['grid_size'], group['mean_l'], marker='s', color=colors[i], linestyle='--', label=f\"Latin-Hypercube Sampling\")\n",
    "    # ax.errorbar(group['grid_size'], group[\"mean_l\"], yerr=np.sqrt(group['variance_l']), fmt='o', color=colors[i], capsize=5)\n",
    "\n",
    "    ax.plot(group['grid_size'], group['mean_r'], marker='v', color=colors[i], linestyle=':', label=f\"Random Sampling\")\n",
    "    # ax.errorbar(group['grid_size'], group[\"mean_r\"], yerr=np.sqrt(group['variance_l']), fmt='o', color=colors[i], capsize=5)\n",
    "\n",
    "    ax.plot(group['grid_size'], group['mean_o'], marker='d', color=colors[i], linestyle='-.', label=f\"Orthogonal Sampling\")\n",
    "    # ax.errorbar(group['grid_size'], group[\"mean_o\"], yerr=np.sqrt(group['variance_o']), fmt='o', color=colors[i], capsize=5)\n",
    "\n",
    "    deterministic_val= grid_sub_df[grid_sub_df[\"max_iterations\"] == name]\n",
    "    ax.plot(group['grid_size'], deterministic_val['diff_true'], marker='o', color=colors[i], label='Deterministic Sampling')\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylabel(\"Mean Error\")\n",
    "    ax.set_title(f\"Iteration Bound: {name}\", fontsize=10)\n",
    "    ax.legend()\n",
    "    i += 1\n",
    "\n",
    "axes[2].set_xlim(95, 5100)\n",
    "custom_ticks = [100, 500, 1000, 5000]\n",
    "axes[2].set_xticks(custom_ticks)  # Set tick positions\n",
    "axes[2].set_xticklabels([f\"${tick}^2$\" for tick in custom_ticks])\n",
    "axes[2].set_xlabel(\"Number of Samples\")\n",
    "fig.suptitle(\"Abosolute Mean Error with True value\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('difference_act_value.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting border (for importance sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_array=get_border_points(500, 2000, 15)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(diff_array[:, 0], diff_array[:, 1], s=0.1, alpha=0.6)\n",
    "plt.title('Border Region in Mandelbrot Set')\n",
    "plt.xlabel('Re(c)')\n",
    "plt.xlim(-2, 1)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.ylabel('Im(c)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"boundary.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Sampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orthogonal Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def partition_func(pars):\n",
    "    '''\n",
    "    This function parallelizes the simulation, by assigning different proc different parametersets. \n",
    "    It utilizes asynchronic parallelization, meaning the output is printed after the task is finished\n",
    "    '''\n",
    "    PROCESSES = 10 \n",
    "    dict_res = {}\n",
    "    with Pool(PROCESSES) as pool:  # Adjust the number of processes as needed \n",
    "        print(\"Starting parallel execution\")\n",
    "        # asynchronyc parallelization\n",
    "        for res in pool.imap_unordered(worker_orthogonal,  pars):\n",
    "            (tot_points, out_points), par = res\n",
    "            dict_res[par] = (tot_points, out_points)\n",
    "            print(f\"Gridsize: {par[0]}, Iteration Bound:{par[1]}, Run: {par[2]}\\n Total points and points inside mandelbrot: {tot_points, out_points}\", flush=True)\n",
    "    return dict_res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # These are the values to experiment with, test with dummy values (these are quicker)\n",
    "    # s_values = [50, 500, 2000]\n",
    "    # grids = [100, 500, 1000, 5000]\n",
    "\n",
    "    # Dummy values\n",
    "    s_values = [10, 50, 60, 70]\n",
    "    grids = [7, 31, 71, 101]\n",
    "    par_combos = []\n",
    "\n",
    "    # make sure the number of procs you use does not exceed the processor count\n",
    "    print(f\"Number of available CPU cores: {os.cpu_count()}\")\n",
    "    \n",
    "    # 10 runs\n",
    "    for i in range(10):\n",
    "        # provide random seed such that random function will be different\n",
    "        random_seed = i+42\n",
    "\n",
    "        # every proc gets a full grid, every proc a different parameter set (defined above)\n",
    "        for g in grids:\n",
    "            for s in s_values:\n",
    "                par_combos.append( (g, s, i, random_seed))\n",
    "\n",
    "    saved_values = {}\n",
    "    saved_values = partition_func(par_combos)\n",
    "\n",
    "    # ensure saving the values with this code:\n",
    "    with open(\"orthogonal_dummy.txt\", \"w\") as file:\n",
    "        file.write(\"grid_size, max_iterations, run, total_points, points_inside\\n\")\n",
    "        for (key1, key2, run), (value1, value2)  in saved_values.items():\n",
    "            file.write(f\"{key1}, {key2}, {run}, {value1}, {value2}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latin hypercube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def partition_func(pars):\n",
    "    '''\n",
    "    This function parallelizes the simulation, by assigning different proc different parametersets. \n",
    "    It utilizes asynchronic parallelization, meaning the output is printed after the task is finished\n",
    "    '''\n",
    "    # max 10 processes\n",
    "    PROCESSES = 10 \n",
    "    dict_res = {}\n",
    "    with Pool(PROCESSES) as pool:  # Adjust the number of processes as needed \n",
    "        print(\"Starting parallel execution\")\n",
    "        for res in pool.imap_unordered(worker_LHS,  pars):\n",
    "            (tot_points, out_points), par = res\n",
    "            dict_res[par] = (tot_points, out_points)\n",
    "            print(f\"Gridsize: {par[0]}, Iteration Bound:{par[1]}, Run: {par[2]}\\n Total points and points inside mandelbrot: {tot_points, out_points}\", flush=True)\n",
    "    return dict_res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # These are the values to experiment with, test with dummy values (these are quicker)\n",
    "    s_values = [50, 500, 2000]\n",
    "    grids = [100, 500, 1000, 5000]\n",
    "\n",
    "    # Dummy values\n",
    "    s_values = [10, 50, 60, 70]\n",
    "    grids = [7, 31, 71, 101]\n",
    "\n",
    "    par_combos = []\n",
    "    \n",
    "    print(f\"Number of available CPU cores: {os.cpu_count()}\")\n",
    "    \n",
    "    # 10 runs\n",
    "    for i in range(10):\n",
    "        # provide random seed such that random function will be different\n",
    "        random_seed = i+42\n",
    "\n",
    "        # every proc gets a full grid, every proc a different parameter set (defined above)\n",
    "        for g in grids:\n",
    "            \n",
    "            for s in s_values:\n",
    "                par_combos.append( (g, s, i, random_seed))\n",
    "\n",
    "    saved_values = {}\n",
    "    saved_values = partition_func(par_combos)\n",
    "\n",
    "    # ensure saving the values with this code:\n",
    "    with open(\"latin-dummy.txt\", \"w\") as file:\n",
    "        # add parameter in case a parameter is added to the \n",
    "        file.write(\"grid_size, max_iterations, run, total_points, points_inside\\n\")\n",
    "        for (key1, key2, run), (value1, value2)  in saved_values.items():\n",
    "            file.write(f\"{key1}, {key2}, {run}, {value1}, {value2}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deterministic Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def partition_grid(grid, proc):\n",
    "    '''\n",
    "    divides the grid evenly through all processes. Row wise partition. \n",
    "    '''\n",
    "    grid_size = grid//proc\n",
    "    rest = grid % proc\n",
    "\n",
    "    indexes =[]\n",
    "    index = 0\n",
    "\n",
    "    real = np.linspace(-2.0, 1.0, grid)\n",
    "    imag = np.linspace(-1.5, 1.5, grid)\n",
    "\n",
    "    # Create a 2D grid of complex numbers c\n",
    "    real_grid, imag_grid = np.meshgrid(real, imag)\n",
    "    c_points = real_grid + 1j * imag_grid\n",
    "\n",
    "    for _ in range(proc):\n",
    "        if rest > 0:\n",
    "            addit = 1\n",
    "            rest -=1\n",
    "        else: \n",
    "            addit = 0\n",
    "        indexes.append((index, index+grid_size+addit))\n",
    "        index += grid_size + addit\n",
    "    \n",
    "    c_slices = [c_points[start:end] for start, end in indexes]\n",
    "    return c_slices\n",
    "\n",
    "\n",
    "def driver_func(grid, s):\n",
    "\n",
    "    # max 10 processes\n",
    "    PROCESSES = 10 \n",
    "    with Pool(PROCESSES) as pool:  # Adjust the number of processes as needed \n",
    "\n",
    "        # every process gets a fraction of the grid (row-wise partitioning)\n",
    "        c_parts = partition_grid(grid, PROCESSES)\n",
    "\n",
    "        args = [(c_slice, s) for c_slice in c_parts]\n",
    "        results = pool.map(worker_function,  args)\n",
    "        total_points_parts, inside_points_parts = zip(*results)\n",
    "        total_points = sum(total_points_parts)\n",
    "        inside_points= sum(inside_points_parts)\n",
    "        print(f\"Result: {results}\\nTotal points and points inside mandelbrot: {total_points, inside_points}\")\n",
    "    return total_points, inside_points\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # # experimental values \n",
    "    # s_values = [10, 20, 50, 100, 150, 250, 500, 1000, 2000]\n",
    "    # grids = [10, 50, 100, 250, 500, 1000, 2000, 5000]\n",
    "    \n",
    "    # dummy values\n",
    "    s_values = [10, 20, 50, 100,]\n",
    "    grids = [10, 50, 100, 250]\n",
    "    \n",
    "    saved_values = {}\n",
    "    # make sure the number of procs you use does not exceed the processor count\n",
    "    print(f\"Number of available CPU cores: {os.cpu_count()}\")\n",
    "    for grid in grids:\n",
    "        for s_value in s_values:\n",
    "            key = (grid, s_value)\n",
    "            tot_points, in_points = driver_func(grid, s_value)\n",
    "            saved_values[key] = (tot_points, in_points)\n",
    "            \n",
    "    with open(\"deterministic-dummy.txt\", \"w\") as file:\n",
    "        file.write(\"grid_size, max_iterations, total_points, points_inside\\n\")\n",
    "        for (key1, key2), (value1, value2)  in saved_values.items():\n",
    "            file.write(f\"{key1}, {key2}, {value1}, {value2}\\n\")\n",
    "\n",
    "#Since the mandelbrot is symmetrical, we could halve the grid and get the same fraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_random(pars):\n",
    "    '''\n",
    "    Assign a task (different parameterset) to every proc once it is free. \n",
    "    Prints output of a task once it is finsihed. \n",
    "    Returns fraction of points outside of mandelbrot as dictionary\n",
    "    '''\n",
    "    PROCESSES = 10\n",
    "    dict_res = {}\n",
    "    with Pool(PROCESSES) as pool:\n",
    "        for res in pool.imap_unordered(worker_pure, pars):\n",
    "            (tot_points, in_points), par = res\n",
    "            dict_res[par] = (tot_points, in_points)\n",
    "            estimated_area = (1-(in_points / tot_points)) * 9\n",
    "            print(f\"Grid-Size: {par[0]}, Iterations: {par[1]}, run: {par[2]}, Area: {estimated_area:.6f}\")\n",
    "    return dict_res\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # variables for experimentation\n",
    "    s_values = [50, 500, 2000]\n",
    "    grids = [100, 500, 1000, 5000]\n",
    "\n",
    "    # dummy values\n",
    "    s_values = [50, 100, 200]\n",
    "    grids = [100, 200, 300]\n",
    "\n",
    "    par_combos = []\n",
    "    for i in range(10):\n",
    "        for size in grids:\n",
    "            for max_iter in s_values:\n",
    "                \n",
    "                # update rand for uniqueness across different runs\n",
    "                rand = 42+i\n",
    "                par_combos.append((size, max_iter, i, rand))\n",
    "    print(f\"Number of available CPU cores: {os.cpu_count()}\")\n",
    "    saved_values = partition_random(par_combos)\n",
    "\n",
    "    dict_temp = {}\n",
    "    # save values to .txt file\n",
    "    with open('random_temp.txt', 'w') as file:\n",
    "        file.write('grid_size, max_iterations, run, total_points, points_inside\\n')\n",
    "        for (key1, key2, key3), (value1, value2) in saved_values.items():\n",
    "            file.write(f\"{key1}, {key2}, {key3}, {value1}, {value2}\\n\")\n",
    "            if (key1, key2) not in dict_temp:\n",
    "                dict_temp[(key1, key2)] = []\n",
    "        \n",
    "            # Append the calculated value to the list\n",
    "            dict_temp[(key1, key2)].append(abs((value1 - value2) / value1 * 9-1.506484))\n",
    "        for (item1, item2), values in dict_temp.items(): \n",
    "            print(f'{item1, item2}, waarde: {np.var(values)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_func(pars, method='random'):\n",
    "    PROCESSES = 14\n",
    "    dict_res = {}\n",
    "    worker_function = (\n",
    "            worker_importance_random if method == 'random'\n",
    "            else worker_importance_LHS if method == 'latin'\n",
    "            else worker_importance_orthogonal\n",
    "        )\n",
    "\n",
    "    with Pool(PROCESSES) as pool:\n",
    "        print(f\"Starting parallel execution for {method} sampling\")\n",
    "        for res in pool.imap_unordered(worker_function,pars):\n",
    "            (tot_points, out_points), par = res\n",
    "            dict_res[par] = (tot_points, out_points)\n",
    "            estimated_area = (tot_points-out_points)/tot_points * 9\n",
    "            print(f\"Method: {method}, Grid-Size: {par[0]}, Iteration Bound: {par[1]}, run: {par[2]}, Area: {estimated_area:.6f}\")\n",
    "    return dict_res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # dummy values\n",
    "    grids = [100, 500] \n",
    "    s_values = [50, 500]\n",
    "\n",
    "    # # experimental values\n",
    "    # grids = [100, 500, 1000, 5000]\n",
    "    # s_values = [50, 500, 2000]\n",
    "    # Add CPU core check\n",
    "    print(f\"Number of available CPU cores: {os.cpu_count()}\")\n",
    "     # Calculate border points once\n",
    "    \n",
    "    # estimate border points an build a tree, use this tree for the distance function -> is used to calculate g(x) upon which is resampled\n",
    "    border_points = get_border_points(500, 2000, 15)\n",
    "    border_tree = cKDTree(border_points)\n",
    "    if border_tree is None: \n",
    "        print(\"Tree Function is not working\")\n",
    "    \n",
    "    par_combos = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        for iter in s_values:\n",
    "            for size in grids:\n",
    "                # ensure uniqueness across runs by updating random seed\n",
    "                rand = 42+i\n",
    "                par_combos.append((size, iter, i, rand, border_points, border_tree))\n",
    "    \n",
    "    # iterate over all methods \n",
    "    methods = [ 'random', 'orthogonal', 'latin'] \n",
    "    \n",
    "    for method in methods:\n",
    "        print(f\"\\nProcessing {method} sampling method...\")\n",
    "        saved_values = partition_func(par_combos, method=method)\n",
    "        \n",
    "        filename = f\"dummy_improved_{method}.txt\"\n",
    "        print(f\"Saving results to {filename}\")\n",
    "        dict_temp = {}\n",
    "        with open(filename, \"w\") as file:\n",
    "            file.write(\"grid_size, iteration bound, run, total_points, points_inside\\n\")\n",
    "            for (key1, key2, key3), (value1, value2) in saved_values.items():\n",
    "                file.write(f\"{key1}, {key2}, {key3}, {value1}, {value2}\\n\")\n",
    "                if (key1, key2) not in dict_temp:\n",
    "                    dict_temp[(key1, key2)] = []\n",
    "        \n",
    "                # Append the calculated value to the list\n",
    "                dict_temp[(key1, key2)].append(abs((value1 - value2) / value1 * 9 - 1.506484))\n",
    "        for (item1, item2), values in dict_temp.items(): \n",
    "            print(f'{item1, item2}, variance: {np.var(values)}')\n",
    "            print(f'{item1, item2}, mean_diff: {np.mean(values)}')\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Deterministic Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a Mandelbrot figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the imaginary point set\n",
    "real = np.linspace(-2.0, 1.0, 1000)\n",
    "imag = np.linspace(-1.5, 1.5, 1000)\n",
    "\n",
    "# Create a 2D grid of complex numbers c\n",
    "real_grid, imag_grid = np.meshgrid(real, imag)\n",
    "c_points = real_grid + 1j * imag_grid\n",
    "\n",
    "max_iter = 250\n",
    "escape_radius = 2\n",
    "\n",
    "mandel_set, iter_count = mandelbrot(c_points, max_iter, escape_radius)\n",
    "\n",
    "plt.figure(figsize=(12, 8), dpi=300)\n",
    "plt.imshow(iter_count, extent=(-2.0, 1.0, -1.5, 1.5), cmap='plasma', origin='lower')\n",
    "plt.xlabel(\"Re(c)\")\n",
    "plt.ylabel(\"Im(c)\")\n",
    "plt.title(\"Mandelbrot Set\")\n",
    "plt.colorbar(label=\"In Mandelbrot Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mandelbrot_iteration(c, max_iter, escape_radius):\n",
    "    z = 0\n",
    "    for n in range(max_iter):\n",
    "        z = z*z + c\n",
    "        if abs(z) > escape_radius:\n",
    "            return n\n",
    "    return max_iter\n",
    "\n",
    "def compute_mandelbrot(real, imag, max_iter, escape_radius):\n",
    "    height, width = len(imag), len(real)\n",
    "    iteration_count = np.zeros((height, width), dtype=np.int64)\n",
    "    \n",
    "    # Create a mesh grid for vectorized computation\n",
    "    real_grid, imag_grid = np.meshgrid(real, imag)\n",
    "    c = real_grid + 1j * imag_grid\n",
    "    z = np.zeros_like(c, dtype=np.complex128)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        mask = np.abs(z) <= escape_radius\n",
    "        z[mask] = z[mask]**2 + c[mask]\n",
    "        iteration_count[mask] = i\n",
    "    \n",
    "    # Set points that never escaped to max_iter\n",
    "    iteration_count[np.abs(z) <= escape_radius] = max_iter\n",
    "    \n",
    "    return iteration_count\n",
    "\n",
    "def create_custom_colormap():\n",
    "    # Create colors for our custom colormap\n",
    "    colors = []\n",
    "    for i in range(256):\n",
    "        # Convert HSV to RGB, cycling through hues\n",
    "        hue = i/256\n",
    "        saturation = 1.0\n",
    "        value = 1.0 if i > 10 else i/10.0  # Darker colors for low iteration counts\n",
    "        rgb = colorsys.hsv_to_rgb(hue, saturation, value)\n",
    "        colors.append(rgb)\n",
    "    \n",
    "    # Add black for the Mandelbrot set itself\n",
    "    colors.append((0, 0, 0))\n",
    "    \n",
    "    return LinearSegmentedColormap.from_list('custom', colors)\n",
    "\n",
    "def plot_mandelbrot(iteration_count, real_range, imag_range, max_iter, \n",
    "                   zoom_center=None, zoom_width=None, title=\"Enhanced Mandelbrot Set\"):\n",
    "    plt.figure(figsize=(15, 10), dpi=300)\n",
    "    \n",
    "    # Create the plot with a custom colormap\n",
    "    custom_cmap = create_custom_colormap()\n",
    "    \n",
    "    # Normalize iteration counts for smoother color transitions\n",
    "    smooth_iter = iteration_count + 1 - np.log(np.log(np.abs(iteration_count)))/np.log(2)\n",
    "    smooth_iter[iteration_count == max_iter] = max_iter\n",
    "    \n",
    "    # Plot with enhanced aesthetics\n",
    "    plt.imshow(smooth_iter, \n",
    "              extent=(real_range[0], real_range[-1], imag_range[0], imag_range[-1]),\n",
    "              cmap=custom_cmap,\n",
    "              origin='lower',\n",
    "              aspect='equal')\n",
    "    \n",
    "    # Add gridlines\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Enhance labels and title\n",
    "    plt.xlabel(\"Re(c)\", fontsize=12)\n",
    "    plt.ylabel(\"Im(c)\", fontsize=12)\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    \n",
    "    # Add colorbar with custom label\n",
    "    cbar = plt.colorbar(label=\"Iteration Count\", pad=0.02)\n",
    "    cbar.ax.set_ylabel(\"Iteration Count\", fontsize=10)\n",
    "    \n",
    "    # Add zoom box if specified\n",
    "    if zoom_center and zoom_width:\n",
    "        zoom_rect = plt.Rectangle(\n",
    "            (zoom_center[0] - zoom_width/2, zoom_center[1] - zoom_width/2),\n",
    "            zoom_width, zoom_width,\n",
    "            fill=False, color='white', linestyle='--'\n",
    "        )\n",
    "        plt.gca().add_patch(zoom_rect)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "# Parameters for the main plot\n",
    "# Reduced resolution for faster computation since we don't have Numba\n",
    "real = np.linspace(-2.0, 1.0, 1000)  \n",
    "imag = np.linspace(-1.5, 1.5, 1000)\n",
    "max_iter = 1000\n",
    "escape_radius = 2.0\n",
    "\n",
    "# Compute the main Mandelbrot set\n",
    "iteration_count = compute_mandelbrot(real, imag, max_iter, escape_radius)\n",
    "\n",
    "# Create main plot\n",
    "main_plot = plot_mandelbrot(iteration_count, real, imag, max_iter, \n",
    "                           title=\"The Mandelbrot Set\")\n",
    "plt.show()\n",
    "\n",
    "# Create a zoomed plot of an interesting region\n",
    "zoom_center = (-0.7435, 0.1314)\n",
    "zoom_width = 0.002\n",
    "\n",
    "# Calculate new ranges for zoom\n",
    "zoom_real = np.linspace(zoom_center[0] - zoom_width/2, \n",
    "                       zoom_center[0] + zoom_width/2, 1000)\n",
    "zoom_imag = np.linspace(zoom_center[1] - zoom_width/2, \n",
    "                       zoom_center[1] + zoom_width/2, 1000)\n",
    "\n",
    "# Compute zoomed region\n",
    "zoom_iteration_count = compute_mandelbrot(zoom_real, zoom_imag, max_iter, escape_radius)\n",
    "\n",
    "# Create zoomed plot\n",
    "zoom_plot = plot_mandelbrot(zoom_iteration_count, zoom_real, zoom_imag, max_iter,\n",
    "                           title=f\"Mandelbrot Set Zoom (width={zoom_width:.6f})\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probabil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
