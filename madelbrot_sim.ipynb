{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Mandelbrot Set Iteration\n",
    "\n",
    "The Mandelbrot set is given as the iteration of the following equations\n",
    "$$\n",
    "z_{n+1} = z^2_n + c\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $z_0$ = 0 (starting value)\n",
    "* $c$ is a complex number, where each unique $c$ will yield a different sequence of $z$ values\n",
    "\n",
    "A point $c$ is in the Mandelbort set if, after iterating the equation multiple times, $|z|$ (the magnitude of $Z$) stays bounded (specifically, it remains $\\leq$ 2). If $|z|$ escapes beyond 2, $c$ is not part of the set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from worker import worker_function\n",
    "from worker import worker_pure\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import sys\n",
    "from worker import worker_function_sampling\n",
    "from worker import worker_orthogonal\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mandelbrot(c_points, max_iter, escape_radius) -> tuple[np.array, np.array]:\n",
    "    '''\n",
    "    This function calculates the number of iterations until the magnitude of z escapes to infinity. \n",
    "    Within each iteration the z is updated with c, an imaginary number representing a grid point. \n",
    "    Ultimately, a mandelbrot is calculated. \n",
    "    '''\n",
    "    iteration_count = np.zeros(c_points.shape)\n",
    "    mandelbrot_set = np.zeros(c_points.shape, dtype=bool)\n",
    "    for i in range(c_points.shape[0]):\n",
    "        for j in range(c_points.shape[1]):\n",
    "\n",
    "            # take a gridpoint\n",
    "            c = c_points[i, j]\n",
    "            z = 0\n",
    "            for iteration in range(max_iter):\n",
    "\n",
    "                # update of z\n",
    "                z = z**2 + c\n",
    "                if abs(z) > escape_radius:\n",
    "                    mandelbrot_set[i, j] = False\n",
    "                    iteration_count[i, j] =iteration\n",
    "                    break\n",
    "            else:\n",
    "                mandelbrot_set[i, j] = True\n",
    "                iteration_count[i, j] = max_iter\n",
    "    return (mandelbrot_set, iteration_count)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting different layouts of sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worker import get_example_samples\n",
    "\n",
    "\n",
    "samples = 9 #root needs to be an int\n",
    "random_seed = 57\n",
    "(orth_samples, latin_samles, random_samples) = get_example_samples(samples, random_seed)\n",
    "\n",
    "headers = ['Orthogonal', 'Latin Hypercube', 'Random', 'Deterministic' ]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(5, 5), sharey=True, sharex=True)\n",
    "\n",
    "real = np.linspace(-2.0, 1.0, int(np.sqrt(samples)))\n",
    "imag = np.linspace(-1.5, 1.5, int(np.sqrt(samples)))\n",
    "\n",
    "real_grid, imag_grid = np.meshgrid(real, imag)\n",
    "coordinates_det = np.array(list(zip(real_grid.flatten(), imag_grid.flatten())))\n",
    "\n",
    "\n",
    "j = 0\n",
    "i = 0\n",
    "for k, coordinates in enumerate([orth_samples, latin_samles, random_samples, coordinates_det]):\n",
    "    if j == 0:\n",
    "        if i > 1: \n",
    "            j += 1\n",
    "            i -= 2\n",
    "    \n",
    "    ax = axes[i][j]\n",
    "    ax.scatter(coordinates[:, 0], coordinates[:, 1])\n",
    "    ax.set_xlim(-2, 1)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "\n",
    "    ax.set_aspect('equal', adjustable='box')  # Ensures 1:1 aspect ratio\n",
    "\n",
    "    ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)   # Thinner minor grid\n",
    "\n",
    "    ax.set_xticks(np.linspace(-2, 1, samples+1), minor=True)  \n",
    "    ax.set_yticks(np.linspace(-1.5, 1.5, samples+1), minor=True)\n",
    "\n",
    "    ax.grid(which='major', color='black', linestyle='-', linewidth=1.5)  # Thicker major grid every 3 cells\n",
    "    ax.set_xticks(np.linspace(-2, 1, int(samples/np.sqrt(samples)) + 1, endpoint=True))  \n",
    "    ax.set_yticks(np.linspace(-1.5, 1.5, int(samples/np.sqrt(samples))+1, endpoint=True))\n",
    "\n",
    "    ax.set_title(headers[k])\n",
    "    # ax.miminorticks_on()\n",
    "    i+=1\n",
    "\n",
    "fig.suptitle('Different Monte Carlo Sampling Methods', fontsize=14)\n",
    "plt.savefig(\"Sampling_layout.png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading .txt file and processing data of the sampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the results from deterministic sampling, Area as a function of the grid-size\n",
    "df = pd.read_csv(\"question2.txt\", delimiter=\",\", skiprows=1,\n",
    "                 names=[\"grid_size\", \"max_iterations\", \"total_points\", \"points_inside\"])\n",
    "df[\"fraction_mand\"] = (1 - df[\"points_inside\"]/df[\"total_points\"])*9\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(4.3, 11))\n",
    "for max_iter, group in df.groupby(\"max_iterations\"):\n",
    "    ax1.plot(group[\"grid_size\"], group[\"fraction_mand\"], label=f\"{max_iter}\", marker= 'o')\n",
    "    ax2.plot(group[\"grid_size\"], group[\"fraction_mand\"], label=f\"{max_iter}\", marker= 'o')\n",
    "    ax3.plot(group[\"grid_size\"], group[\"fraction_mand\"], label=f\"{max_iter}\", marker= 'o')\n",
    "\n",
    "# full plot\n",
    "ax1.set_ylabel(\"Area of Mandelbrot\")\n",
    "ax1.set_title(\"Full Size\")\n",
    "ax1.legend(title=\"Iteration Bound\")\n",
    "ax1.set_xlim(0, 5040)\n",
    "ax1.grid(True)\n",
    "\n",
    "# for max_iter, group in df.groupby(\"max_iterations\"):\n",
    "    \n",
    "\n",
    "# zoomed in plot on the y-axes\n",
    "ax2.set_ylabel(\"Area of Mandelbrot\")\n",
    "ax2.set_title(\"Zoomed In (y-Axes)\")\n",
    "ax2.set_xlim(0, 5040)\n",
    "ax2.grid(True)\n",
    "ax2.set_ylim(0.165*9, 0.1735*9)\n",
    "\n",
    "# zooming in on x-axes\n",
    "ax3.set_ylabel(\"Area of Mandelbrot\")\n",
    "ax3.set_xlabel(\"Grid Size\")\n",
    "ax3.set_title(\"Zoomed In (x-Axes)\")\n",
    "ax3.set_xlim(0, 5040)\n",
    "ax3.grid(True)\n",
    "ax3.set_xlim(0, 500)\n",
    "\n",
    "fig.suptitle(\"Area of Mandelbrot vs Grid-Size\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Area_deterministic.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_o = pd.read_csv(\"orthogonal.txt\", header=1)  \n",
    "\n",
    "# Assign column labels\n",
    "df_o.columns = [\"grid_size\", \"max_iterations\", \"run\", \"total_points\", \"points_inside\"]\n",
    "# calculating area based on fraction of points inside and outside\n",
    "df_o['fraction'] = (1- df_o['points_inside'] / df_o['total_points'])*9\n",
    "\n",
    "# calculating variance and mean of area\n",
    "average_fraction_o = df_o.groupby(['grid_size', 'max_iterations'])['fraction'].mean()\n",
    "variance_fraction_o = df_o.groupby(['grid_size', 'max_iterations'])['fraction'].var()\n",
    "\n",
    "# saving the variance and mean of different groups for orthogonal in a new dataframe \n",
    "mean_var_o = pd.DataFrame({\n",
    "    'mean': average_fraction_o,\n",
    "    'variance': variance_fraction_o\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "colors = [\"orange\", \"green\", \"purple\"]\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, sharex= True, figsize=(5,5), gridspec_kw={'height_ratios': [1, 1], 'hspace': 0.05})\n",
    "# bax = brokenaxes(ylims=((1.5, 1.525), (1.58, 1.595)), hspace=.05) \n",
    "i = 0\n",
    "for name, group in mean_var_o.groupby(\"max_iterations\"):\n",
    "    ax1.plot(group['grid_size'], group['mean'], color=colors[i], label=f\"Iteration Bound: {name}\")\n",
    "    ax1.errorbar(group['grid_size'], group[\"mean\"], yerr=np.sqrt(group['variance']), fmt='o-', color=colors[i], capsize=5)\n",
    "\n",
    "    # Plot on ax2 without labels to avoid duplicating in the legend\n",
    "    ax2.plot(group['grid_size'], group['mean'], color=colors[i])\n",
    "    ax2.errorbar(group['grid_size'], group[\"mean\"], yerr=np.sqrt(group['variance']), fmt='o-', color=colors[i], capsize=5)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "ax2.plot(group['grid_size'], [1.506484]*4, color='black', linestyle= '--', label='True Value')\n",
    "ax1.plot(group['grid_size'], [1.506484]*4, color='black', linestyle= '--', label='True Value')\n",
    "ax1.legend()\n",
    "# ax2.legend()\n",
    "\n",
    "ax1.set_ylim(1.58, 1.605)\n",
    "ax2.set_ylim(1.5, 1.525)\n",
    "\n",
    "# Set log scale on x-axis\n",
    "ax1.set_xscale(\"log\")\n",
    "ax2.set_xscale(\"log\")\n",
    "\n",
    "custom_ticks = [100, 500, 1000, 5000]\n",
    "ax2.set_xticks(custom_ticks)  # Set tick positions\n",
    "ax2.set_xticklabels([f\"${tick}^2$\" for tick in custom_ticks])\n",
    "ax2.set_xlabel(\"Sample Size\")\n",
    "fig.suptitle(\"Orthogonal Sampling over 10 Runs\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"orthogonal_mean.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_l = pd.read_csv(\"latin.txt\", header=1)  # Set header=None since there is no header in the file\n",
    "\n",
    "# Assign column labels\n",
    "df_l.columns = [\"grid_size\", \"max_iterations\", \"run\", \"total_points\", \"points_inside\"]\n",
    "df_l['fraction'] = (1- df_l['points_inside'] / df_l['total_points'])*9\n",
    "\n",
    "average_fraction = df_l.groupby(['grid_size', 'max_iterations'])['fraction'].mean()\n",
    "variance_fraction = df_l.groupby(['grid_size', 'max_iterations'])['fraction'].var()\n",
    "\n",
    "# creating a data frame with mean and variance of every group for latin hypercube\n",
    "mean_var_l = pd.DataFrame({\n",
    "    'mean': average_fraction,\n",
    "    'variance': variance_fraction\n",
    "}).reset_index()\n",
    "print(mean_var_l)\n",
    "\n",
    "colors = [\"orange\", \"green\", \"purple\"]\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, sharex= True, figsize=(5,5), gridspec_kw={'height_ratios': [1, 1], 'hspace': 0.05})\n",
    "i = 0\n",
    "for name, group in mean_var_l.groupby(\"max_iterations\"):\n",
    "    ax1.plot(group['grid_size'], group['mean'], color=colors[i], label=f\"Iteration Bound: {name}\")\n",
    "    ax1.errorbar(group['grid_size'], group[\"mean\"], yerr=np.sqrt(group['variance']), fmt='o-', color=colors[i], capsize=5)\n",
    "\n",
    "    # Plot on ax2 without labels to avoid duplicating in the legend\n",
    "    ax2.plot(group['grid_size'], group['mean'], color=colors[i])\n",
    "    ax2.errorbar(group['grid_size'], group[\"mean\"], yerr=np.sqrt(group['variance']), fmt='o-', color=colors[i], capsize=5)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# plotting true value\n",
    "ax2.plot(group['grid_size'], [1.506484]*4, color='black', linestyle= '--', label='True Value')\n",
    "ax1.plot(group['grid_size'], [1.506484]*4, color='black', linestyle= '--', label='True Value')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot finetuning\n",
    "ax1.set_ylim(1.56, 1.63)\n",
    "ax2.set_ylim(1.48, 1.55)\n",
    "ax1.set_xscale(\"log\")\n",
    "ax2.set_xscale(\"log\")\n",
    "\n",
    "custom_ticks = [100, 500, 1000, 5000]\n",
    "ax2.set_xticks(custom_ticks)  # Set tick positions\n",
    "ax2.set_xticklabels([f\"${tick}^2$\" for tick in custom_ticks])\n",
    "ax2.set_xlabel(\"Sample Size\")\n",
    "fig.suptitle(\"Latin Hypercube Sampling over 10 Runs\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Latin_mean.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_r = pd.read_csv(\"random.txt\", header=1)  # Set header=None since there is no header in the file\n",
    "\n",
    "# Assign column labels\n",
    "df_r.columns = [\"grid_size\", \"max_iterations\", \"run\", \"total_points\", \"points_inside\"]\n",
    "\n",
    "# calculate area with fraction inside and outside mandelbrot\n",
    "df_r['fraction'] = (1- df_r['points_inside'] / df_r['total_points'])*9\n",
    "\n",
    "\n",
    "# calculating fraction and variance\n",
    "average_fraction = df_r.groupby(['grid_size', 'max_iterations'])['fraction'].mean()\n",
    "variance_fraction = df_r.groupby(['grid_size', 'max_iterations'])['fraction'].var()\n",
    "\n",
    "# creating data frame of mean and variance of data from different groups within random sampling\n",
    "mean_var = pd.DataFrame({\n",
    "    'mean': average_fraction,\n",
    "    'variance': variance_fraction\n",
    "}).reset_index()\n",
    "\n",
    "colors = [\"orange\", \"green\", \"purple\"]\n",
    "fig, ax = plt.subplots(1,1, sharex= True, figsize=(4.8,4.8))\n",
    "i = 0\n",
    "\n",
    "# plot mean and std for every line\n",
    "for name, group in mean_var.groupby(\"max_iterations\"):\n",
    "    ax.plot(group['grid_size'], group['mean'], color=colors[i], label=f\"Iteration Bound: {name}\")\n",
    "    ax.errorbar(group['grid_size'], group[\"mean\"], yerr=np.sqrt(group['variance']), fmt='o-', color=colors[i], capsize=5)\n",
    "    i += 1\n",
    "\n",
    "ax.plot(group['grid_size'], [1.506484]*4, color='black', linestyle= '--', label='True Value')\n",
    "ax.legend()\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "custom_ticks = [100, 500, 1000, 5000]\n",
    "ax.set_xticks(custom_ticks)  # Set tick positions\n",
    "ax.set_xticklabels([f\"${tick}^2$\" for tick in custom_ticks])\n",
    "ax.set_xlabel(\"Sample Size\")\n",
    "fig.suptitle(\"Random Sampling over 10 Runs\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"random_sampling.png\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(4.5, 9), sharex=True)\n",
    "fig.suptitle(\"Variance for Monte Carlo Sampling\")\n",
    "\n",
    "# Plot for Random Sampling\n",
    "\n",
    "for j, m_v in enumerate([mean_var, mean_var_l, mean_var_o]):\n",
    "    i = 0\n",
    "    for name, group in m_v.groupby(\"max_iterations\"):\n",
    "        axes[j].plot(group[\"grid_size\"], group['variance'], marker='o', color=colors[i], label=f'Iteration Bound {name}')\n",
    "        i += 1\n",
    "    # axes[j].set_xlabel(\"Sample Size\")\n",
    "    axes[j].set_yscale(\"log\")\n",
    "    axes[j].set_ylabel(\"Variance\")\n",
    "\n",
    "axes[0].set_title(\"Random Sampling\")\n",
    "axes[0].legend()\n",
    "axes[1].set_title(\"Latin Hyper-Cube Sampling\")\n",
    "axes[2].set_title(\"Orthogonal Sampling\")\n",
    "\n",
    "axes[2].set_xlabel(\"Sample Size\")\n",
    "axes[2].set_xticks([100, 500, 1000, 5000])\n",
    "axes[2].set_xticklabels([f\"${tick}^2$\" for tick in [100, 500, 1000, 5000]], rotation=45)\n",
    "plt.tight_layout()  # Adjust layout to fit the main title\n",
    "plt.savefig('variances.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting mean absolute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"question2.txt\", delimiter=\",\", skiprows=1,\n",
    "                 names=[\"grid_size\", \"max_iterations\", \"total_points\", \"points_inside\"])\n",
    "df[\"fraction\"] = (1 - df[\"points_inside\"]/df[\"total_points\"])*9\n",
    "true_value = [1.506484]*len(df['fraction'])\n",
    "df[\"diff_true\"] = np.abs(true_value-df['fraction'])\n",
    "\n",
    "\n",
    "true_value = [1.506484]*len(df_l['fraction'])\n",
    "df_l[\"diff_true\"] = np.abs(true_value-df_l['fraction'])\n",
    "average_diff_l = df_l.groupby(['grid_size', 'max_iterations'])['diff_true'].mean()\n",
    "variance_diff_l = df_l.groupby(['grid_size', 'max_iterations'])['diff_true'].var()\n",
    "\n",
    "\n",
    "true_value = [1.506484]*len(df_o['fraction'])\n",
    "df_o[\"diff_true\"] = np.abs(true_value-df_o['fraction'])\n",
    "\n",
    "average_diff_o = df_o.groupby(['grid_size', 'max_iterations'])['diff_true'].mean()\n",
    "variance_diff_o = df_o.groupby(['grid_size', 'max_iterations'])['diff_true'].var()\n",
    "\n",
    "true_value = [1.506484]*len(df_r['fraction'])\n",
    "df_r[\"diff_true\"] = np.abs(true_value-df_r['fraction'])\n",
    "\n",
    "average_diff_r = df_r.groupby(['grid_size', 'max_iterations'])['diff_true'].mean()\n",
    "variance_diff_r = df_r.groupby(['grid_size', 'max_iterations'])['diff_true'].var()\n",
    "\n",
    "mean_var_diff = pd.DataFrame({\n",
    "    'mean_o': average_diff_o,\n",
    "    'variance_o': variance_diff_o,\n",
    "    'mean_l': average_diff_l,\n",
    "    'variance_l': variance_diff_l, \n",
    "    'mean_r': average_diff_r,\n",
    "    'variance_r': variance_diff_r\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "grid_sizes = [100, 500, 1000, 5000]\n",
    "grid_sub_df = df[(df['grid_size'].isin(grid_sizes))].reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(3, 1,sharex=True,figsize=(6,9.5), gridspec_kw={'height_ratios': [1.4, 1, 1]})\n",
    "i = 0\n",
    "for name, group in mean_var_diff.groupby(\"max_iterations\"):\n",
    "    ax = axes[i]\n",
    "    ax.plot(group['grid_size'], group['mean_l'], marker='s', color=colors[i], linestyle='--', label=f\"Latin-Hypercube Sampling\")\n",
    "    # ax.errorbar(group['grid_size'], group[\"mean_l\"], yerr=np.sqrt(group['variance_l']), fmt='o', color=colors[i], capsize=5)\n",
    "\n",
    "    ax.plot(group['grid_size'], group['mean_r'], marker='v', color=colors[i], linestyle=':', label=f\"Random Sampling\")\n",
    "    # ax.errorbar(group['grid_size'], group[\"mean_r\"], yerr=np.sqrt(group['variance_l']), fmt='o', color=colors[i], capsize=5)\n",
    "\n",
    "    ax.plot(group['grid_size'], group['mean_o'], marker='d', color=colors[i], linestyle='-.', label=f\"Orthogonal Sampling\")\n",
    "    # ax.errorbar(group['grid_size'], group[\"mean_o\"], yerr=np.sqrt(group['variance_o']), fmt='o', color=colors[i], capsize=5)\n",
    "\n",
    "    deterministic_val= grid_sub_df[grid_sub_df[\"max_iterations\"] == name]\n",
    "    ax.plot(group['grid_size'], deterministic_val['diff_true'], marker='o', color=colors[i], label='Deterministic Sampling')\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylabel(\"Mean Error\")\n",
    "    ax.set_title(f\"Iteration Bound: {name}\", fontsize=10)\n",
    "    ax.legend()\n",
    "    i += 1\n",
    "\n",
    "axes[2].set_xlim(95, 5100)\n",
    "custom_ticks = [100, 500, 1000, 5000]\n",
    "axes[2].set_xticks(custom_ticks)  # Set tick positions\n",
    "axes[2].set_xticklabels([f\"${tick}^2$\" for tick in custom_ticks])\n",
    "axes[2].set_xlabel(\"Number of Samples\")\n",
    "fig.suptitle(\"Abosolute Mean Error with True value\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('difference_act_value.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Sampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Framework for Parallelized implementation -> for all sampling\n",
    "Do not forget to add sampling specific code in the worker.py file, and add parameters underneath.   \n",
    "Code is currently running with deterministic function mandelbrot in worker.py. Idea is to replace this function (do not remove mandelbrot tho) with sampling specific function.  \n",
    "Also, in case of changes in worker.py, reload this module, such that notebook refreshes imports and notices changes.  \n",
    "\n",
    "Copy this cell, to keep this framework reusable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import Pool\n",
    "# Import own fucntion from .py file -> write for own sampling method! parameters of this function = grid (already given), max iteration bound (already given), sampling specific parameters (need to be difined still)\n",
    "# Don't forget to also return the parameter values (as specified in example worker function)\n",
    "from worker import worker_function\n",
    "\n",
    "\n",
    "def partition_func(pars):\n",
    "\n",
    "    # max 10 processes\n",
    "    PROCESSES = 10 \n",
    "    dict_res = {}\n",
    "    with Pool(PROCESSES) as pool:  # Adjust the number of processes as needed \n",
    "        results = pool.map(worker_function,  pars)\n",
    "        for res in results:\n",
    "            (tot_points, out_points), par = res\n",
    "            dict_res[par] = (tot_points, out_points)\n",
    "            print(f\"Gridsize: {par[0]}, Iteration Bound:{par[1]}\\nTotal points and points inside mandelbrot: {tot_points, out_points}\")\n",
    "    return dict_res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Specify the s_values and grid sizes you want to experiment with\n",
    "    # add sampling specific parameters, which are used in the worker method. (such as number of random samples taken (suggestion: choose 3 values for this, low, med, high))\n",
    "    # evaluate when stochastic method is better than deterministic one. \n",
    "    \n",
    "    # These are the values to experiment with, test with dummy values (these are quicker)\n",
    "    s_values = [50, 500, 2000]\n",
    "    grids = [100, 1000, 5000]\n",
    "\n",
    "\n",
    "    # Dummy values\n",
    "    s_values = [10, 50, 60, 70]\n",
    "    grids = [10, 50, 100, 150]\n",
    "\n",
    "    par_combos = []\n",
    "\n",
    "    # every proc gets a full grid, every proc a different parameter set (defined above)\n",
    "    # add an extra for loop for an extra parameter\n",
    "    for g in grids:\n",
    "        real = np.linspace(-2.0, 1.0, g)\n",
    "        imag = np.linspace(-1.5, 1.5, g)\n",
    "        real_grid, imag_grid = np.meshgrid(real, imag)\n",
    "        c_points = real_grid + 1j * imag_grid\n",
    "        for s in s_values:\n",
    "            par_combos.append((c_points, g, s))\n",
    "    saved_values = {}\n",
    "    # make sure the number of procs you use does not exceed the processor count\n",
    "\n",
    "    print(f\"Number of available CPU cores: {os.cpu_count()}\")\n",
    "    for i in range(10):\n",
    "        # provide random seed such that random function will be different\n",
    "        random_seed = i+42\n",
    "        par_combos = [(comb, random_seed) for comb in par_combos]\n",
    "        saved_values = partition_func(par_combos)\n",
    "\n",
    "        # ensure saving the values with this code:\n",
    "        # CHANGE FILE NAME!!\n",
    "        with open(\"question3-1.txt\", \"w\") as file:\n",
    "            # add parameter in case a parameter is added to the \n",
    "            if i == 0:\n",
    "                file.write(\"grid_size, max_iterations, total_points, points_inside\\n\")\n",
    "            file.write(f\"run {i}:\")\n",
    "            for (key1, key2), (value1, value2)  in saved_values.items():\n",
    "                file.write(f\"{key1}, {key2}, {value1}, {value2}\\n\")\n",
    "\n",
    "\n",
    "#Since the mandelbrot is symmetrical, we could halve the grid and get the same fraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orthongonal Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def partition_func(pars):\n",
    "    '''\n",
    "    This function parallelizes the simulation, by assigning different proc different parametersets. \n",
    "    It utilizes asynchronic parallelization, meaning the output is printed after the task is finished\n",
    "    '''\n",
    "    PROCESSES = 10 \n",
    "    dict_res = {}\n",
    "    with Pool(PROCESSES) as pool:  # Adjust the number of processes as needed \n",
    "        print(\"Starting parallel execution\")\n",
    "        # asynchronyc parallelization\n",
    "        for res in pool.imap_unordered(worker_orthogonal,  pars):\n",
    "            (tot_points, out_points), par = res\n",
    "            dict_res[par] = (tot_points, out_points)\n",
    "            print(f\"Gridsize: {par[0]}, Iteration Bound:{par[1]}, Run: {par[2]}\\n Total points and points inside mandelbrot: {tot_points, out_points}\", flush=True)\n",
    "    return dict_res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # These are the values to experiment with, test with dummy values (these are quicker)\n",
    "    # s_values = [50, 500, 2000]\n",
    "    # grids = [100, 500, 1000, 5000]\n",
    "\n",
    "    # Dummy values\n",
    "    s_values = [10, 50, 60, 70]\n",
    "    grids = [7, 31, 71, 101]\n",
    "    par_combos = []\n",
    "\n",
    "    # make sure the number of procs you use does not exceed the processor count\n",
    "    print(f\"Number of available CPU cores: {os.cpu_count()}\")\n",
    "    \n",
    "    # 10 runs\n",
    "    for i in range(10):\n",
    "        # provide random seed such that random function will be different\n",
    "        random_seed = i+42\n",
    "\n",
    "        # every proc gets a full grid, every proc a different parameter set (defined above)\n",
    "        for g in grids:\n",
    "            for s in s_values:\n",
    "                par_combos.append( (g, s, i, random_seed))\n",
    "\n",
    "    saved_values = {}\n",
    "    saved_values = partition_func(par_combos)\n",
    "\n",
    "    # ensure saving the values with this code:\n",
    "    with open(\"orthogonal_dummy.txt\", \"w\") as file:\n",
    "        file.write(\"grid_size, max_iterations, run, total_points, points_inside\\n\")\n",
    "        for (key1, key2, run), (value1, value2)  in saved_values.items():\n",
    "            file.write(f\"{key1}, {key2}, {run}, {value1}, {value2}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def partition_func(pars):\n",
    "    '''\n",
    "    This function parallelizes the simulation, by assigning different proc different parametersets. \n",
    "    It utilizes asynchronic parallelization, meaning the output is printed after the task is finished\n",
    "    '''\n",
    "    # max 10 processes\n",
    "    PROCESSES = 10 \n",
    "    dict_res = {}\n",
    "    with Pool(PROCESSES) as pool:  # Adjust the number of processes as needed \n",
    "        print(\"Starting parallel execution\")\n",
    "        for res in pool.imap_unordered(worker_function_sampling,  pars):\n",
    "            (tot_points, out_points), par = res\n",
    "            dict_res[par] = (tot_points, out_points)\n",
    "            print(f\"Gridsize: {par[0]}, Iteration Bound:{par[1]}, Run: {par[2]}\\n Total points and points inside mandelbrot: {tot_points, out_points}\", flush=True)\n",
    "    return dict_res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # These are the values to experiment with, test with dummy values (these are quicker)\n",
    "    s_values = [50, 500, 2000]\n",
    "    grids = [100, 500, 1000, 5000]\n",
    "\n",
    "    # Dummy values\n",
    "    s_values = [10, 50, 60, 70]\n",
    "    grids = [7, 31, 71, 101]\n",
    "\n",
    "    par_combos = []\n",
    "    \n",
    "    print(f\"Number of available CPU cores: {os.cpu_count()}\")\n",
    "    \n",
    "    # 10 runs\n",
    "    for i in range(10):\n",
    "        # provide random seed such that random function will be different\n",
    "        random_seed = i+42\n",
    "\n",
    "        # every proc gets a full grid, every proc a different parameter set (defined above)\n",
    "        # add an extra for loop for an extra parameter\n",
    "        for g in grids:\n",
    "            \n",
    "            # print(c_points)\n",
    "            for s in s_values:\n",
    "                par_combos.append( (g, s, i, random_seed))\n",
    "\n",
    "    saved_values = {}\n",
    "    saved_values = partition_func(par_combos)\n",
    "\n",
    "    # ensure saving the values with this code:\n",
    "    with open(\"latin-dummy.txt\", \"w\") as file:\n",
    "        # add parameter in case a parameter is added to the \n",
    "        file.write(\"grid_size, max_iterations, run, total_points, points_inside\\n\")\n",
    "        for (key1, key2, run), (value1, value2)  in saved_values.items():\n",
    "            file.write(f\"{key1}, {key2}, {run}, {value1}, {value2}\\n\")\n",
    "\n",
    "\n",
    "#Since the mandelbrot is symmetrical, we could halve the grid and get the same fraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_size = np.linspace(4, )\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from worker import worker_function\n",
    "\n",
    "def partition_grid(grid, proc):\n",
    "    grid_size = grid//proc\n",
    "    rest = grid % proc\n",
    "\n",
    "    indexes =[]\n",
    "    index = 0\n",
    "\n",
    "    real = np.linspace(-2.0, 1.0, grid)\n",
    "    imag = np.linspace(-1.5, 1.5, grid)\n",
    "\n",
    "    # Create a 2D grid of complex numbers c\n",
    "    real_grid, imag_grid = np.meshgrid(real, imag)\n",
    "    c_points = real_grid + 1j * imag_grid\n",
    "\n",
    "    for _ in range(proc):\n",
    "        if rest > 0:\n",
    "            addit = 1\n",
    "            rest -=1\n",
    "        else: \n",
    "            addit = 0\n",
    "        indexes.append((index, index+grid_size+addit))\n",
    "        index += grid_size + addit\n",
    "    \n",
    "    c_slices = [c_points[start:end] for start, end in indexes]\n",
    "    return c_slices\n",
    "\n",
    "\n",
    "def driver_func(grid, s):\n",
    "\n",
    "    # max 10 processes\n",
    "    PROCESSES = 10 \n",
    "    with Pool(PROCESSES) as pool:  # Adjust the number of processes as needed \n",
    "        pid = os.getpid()\n",
    "        # print(f\"Current Process ID: {pid}\")\n",
    "\n",
    "        # every process gets a fraction of the grid (row-wise partitioning)\n",
    "        c_parts = partition_grid(grid, PROCESSES)\n",
    "\n",
    "        args = [(c_slice, s) for c_slice in c_parts]\n",
    "        results = pool.map(worker_function,  args)\n",
    "        total_points_parts, inside_points_parts = zip(*results)\n",
    "        total_points = sum(total_points_parts)\n",
    "        inside_points= sum(inside_points_parts)\n",
    "        print(f\"Result: {results}\\nTotal points and points inside mandelbrot: {total_points, inside_points}\")\n",
    "    return total_points, inside_points\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    s_values = [10, 20, 50, 100, 150, 250, 500, 1000, 2000]\n",
    "    grids = [10, 50, 100, 250, 500, 1000, 2000, 5000]\n",
    "    \n",
    "    saved_values = {}\n",
    "    # make sure the number of procs you use does not exceed the processor count\n",
    "    print(f\"Number of available CPU cores: {os.cpu_count()}\")\n",
    "    for grid in grids:\n",
    "        for s_value in s_values:\n",
    "            key = (grid, s_value)\n",
    "            tot_points, in_points = driver_func(grid, s_value)\n",
    "            saved_values[key] = (tot_points, in_points)\n",
    "            \n",
    "    with open(\"question2.txt\", \"w\") as file:\n",
    "        file.write(\"grid_size, max_iterations, total_points, points_inside\\n\")\n",
    "        for (key1, key2), (value1, value2)  in saved_values.items():\n",
    "            file.write(f\"{key1}, {key2}, {value1}, {value2}\\n\")\n",
    "\n",
    "#Since the mandelbrot is symmetrical, we could halve the grid and get the same fraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_random(pars):\n",
    "    '''\n",
    "    This function parallelizes the simulation, by assigning different proc different parametersets. \n",
    "    It utilizes asynchronic parallelization, meaning the output is printed after the task is finished\n",
    "    '''\n",
    "    PROCESSES = 10\n",
    "    dict_res = {}\n",
    "    with Pool(PROCESSES) as pool:\n",
    "        for res in pool.imap_unordered(worker_pure, pars):\n",
    "            (tot_points, in_points), par = res\n",
    "            dict_res[par] = (tot_points, in_points)\n",
    "            estimated_area = (1-(in_points / tot_points)) * 9\n",
    "            print(f\"Grid-Size: {par[0]}, Iterations: {par[1]}, run: {par[2]}, Area: {estimated_area:.6f}\")\n",
    "    return dict_res\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # variables for experimentation\n",
    "    s_values = [50, 500, 2000]\n",
    "    grids = [100, 500, 1000, 5000]\n",
    "\n",
    "    # dummy values\n",
    "    s_values = [50, 100, 200]\n",
    "    grids = [100, 200, 300]\n",
    "\n",
    "    par_combos = []\n",
    "    for i in range(10):\n",
    "        for size in grids:\n",
    "            for max_iter in s_values:\n",
    "                \n",
    "                # update rand for uniqueness across different runs\n",
    "                rand = 42+i\n",
    "                par_combos.append((size, max_iter, i, rand))\n",
    "    print(f\"Number of available CPU cores: {os.cpu_count()}\")\n",
    "    saved_values = partition_random(par_combos)\n",
    "\n",
    "    #save values\n",
    "    with open('random_dummy.txt', 'w') as file:\n",
    "        file.write('grid_size, max_iterations, run, total_points, points_inside\\n')\n",
    "        for (key1, key2, key3), (value1, value2) in saved_values.items():\n",
    "            file.write(f\"{key1}, {key2}, {key3}, {value1}, {value2}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a Mandelbrot figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the imaginary point set\n",
    "real = np.linspace(-2.0, 1.0, 1000)\n",
    "imag = np.linspace(-1.5, 1.5, 1000)\n",
    "\n",
    "# Create a 2D grid of complex numbers c\n",
    "real_grid, imag_grid = np.meshgrid(real, imag)\n",
    "c_points = real_grid + 1j * imag_grid\n",
    "\n",
    "max_iter = 250\n",
    "escape_radius = 2\n",
    "\n",
    "mandel_set, iter_count = mandelbrot(c_points, max_iter, escape_radius)\n",
    "\n",
    "plt.figure(figsize=(12, 8), dpi=300)\n",
    "plt.imshow(iter_count, extent=(-2.0, 1.0, -1.5, 1.5), cmap='plasma', origin='lower')\n",
    "plt.xlabel(\"Re(c)\")\n",
    "plt.ylabel(\"Im(c)\")\n",
    "plt.title(\"Mandelbrot Set\")\n",
    "plt.colorbar(label=\"In Mandelbrot Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import colorsys\n",
    "\n",
    "def mandelbrot_iteration(c, max_iter, escape_radius):\n",
    "    z = 0\n",
    "    for n in range(max_iter):\n",
    "        z = z*z + c\n",
    "        if abs(z) > escape_radius:\n",
    "            return n\n",
    "    return max_iter\n",
    "\n",
    "def compute_mandelbrot(real, imag, max_iter, escape_radius):\n",
    "    height, width = len(imag), len(real)\n",
    "    iteration_count = np.zeros((height, width), dtype=np.int64)\n",
    "    \n",
    "    # Create a mesh grid for vectorized computation\n",
    "    real_grid, imag_grid = np.meshgrid(real, imag)\n",
    "    c = real_grid + 1j * imag_grid\n",
    "    z = np.zeros_like(c, dtype=np.complex128)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        mask = np.abs(z) <= escape_radius\n",
    "        z[mask] = z[mask]**2 + c[mask]\n",
    "        iteration_count[mask] = i\n",
    "    \n",
    "    # Set points that never escaped to max_iter\n",
    "    iteration_count[np.abs(z) <= escape_radius] = max_iter\n",
    "    \n",
    "    return iteration_count\n",
    "\n",
    "def create_custom_colormap():\n",
    "    # Create colors for our custom colormap\n",
    "    colors = []\n",
    "    for i in range(256):\n",
    "        # Convert HSV to RGB, cycling through hues\n",
    "        hue = i/256\n",
    "        saturation = 1.0\n",
    "        value = 1.0 if i > 10 else i/10.0  # Darker colors for low iteration counts\n",
    "        rgb = colorsys.hsv_to_rgb(hue, saturation, value)\n",
    "        colors.append(rgb)\n",
    "    \n",
    "    # Add black for the Mandelbrot set itself\n",
    "    colors.append((0, 0, 0))\n",
    "    \n",
    "    return LinearSegmentedColormap.from_list('custom', colors)\n",
    "\n",
    "def plot_mandelbrot(iteration_count, real_range, imag_range, max_iter, \n",
    "                   zoom_center=None, zoom_width=None, title=\"Enhanced Mandelbrot Set\"):\n",
    "    plt.figure(figsize=(15, 10), dpi=300)\n",
    "    \n",
    "    # Create the plot with a custom colormap\n",
    "    custom_cmap = create_custom_colormap()\n",
    "    \n",
    "    # Normalize iteration counts for smoother color transitions\n",
    "    smooth_iter = iteration_count + 1 - np.log(np.log(np.abs(iteration_count)))/np.log(2)\n",
    "    smooth_iter[iteration_count == max_iter] = max_iter\n",
    "    \n",
    "    # Plot with enhanced aesthetics\n",
    "    plt.imshow(smooth_iter, \n",
    "              extent=(real_range[0], real_range[-1], imag_range[0], imag_range[-1]),\n",
    "              cmap=custom_cmap,\n",
    "              origin='lower',\n",
    "              aspect='equal')\n",
    "    \n",
    "    # Add gridlines\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Enhance labels and title\n",
    "    plt.xlabel(\"Re(c)\", fontsize=12)\n",
    "    plt.ylabel(\"Im(c)\", fontsize=12)\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    \n",
    "    # Add colorbar with custom label\n",
    "    cbar = plt.colorbar(label=\"Iteration Count\", pad=0.02)\n",
    "    cbar.ax.set_ylabel(\"Iteration Count\", fontsize=10)\n",
    "    \n",
    "    # Add zoom box if specified\n",
    "    if zoom_center and zoom_width:\n",
    "        zoom_rect = plt.Rectangle(\n",
    "            (zoom_center[0] - zoom_width/2, zoom_center[1] - zoom_width/2),\n",
    "            zoom_width, zoom_width,\n",
    "            fill=False, color='white', linestyle='--'\n",
    "        )\n",
    "        plt.gca().add_patch(zoom_rect)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "# Parameters for the main plot\n",
    "# Reduced resolution for faster computation since we don't have Numba\n",
    "real = np.linspace(-2.0, 1.0, 1000)  \n",
    "imag = np.linspace(-1.5, 1.5, 1000)\n",
    "max_iter = 1000\n",
    "escape_radius = 2.0\n",
    "\n",
    "# Compute the main Mandelbrot set\n",
    "iteration_count = compute_mandelbrot(real, imag, max_iter, escape_radius)\n",
    "\n",
    "# Create main plot\n",
    "main_plot = plot_mandelbrot(iteration_count, real, imag, max_iter, \n",
    "                           title=\"The Mandelbrot Set\")\n",
    "plt.show()\n",
    "\n",
    "# Create a zoomed plot of an interesting region\n",
    "zoom_center = (-0.7435, 0.1314)\n",
    "zoom_width = 0.002\n",
    "\n",
    "# Calculate new ranges for zoom\n",
    "zoom_real = np.linspace(zoom_center[0] - zoom_width/2, \n",
    "                       zoom_center[0] + zoom_width/2, 1000)\n",
    "zoom_imag = np.linspace(zoom_center[1] - zoom_width/2, \n",
    "                       zoom_center[1] + zoom_width/2, 1000)\n",
    "\n",
    "# Compute zoomed region\n",
    "zoom_iteration_count = compute_mandelbrot(zoom_real, zoom_imag, max_iter, escape_radius)\n",
    "\n",
    "# Create zoomed plot\n",
    "zoom_plot = plot_mandelbrot(zoom_iteration_count, zoom_real, zoom_imag, max_iter,\n",
    "                           title=f\"Mandelbrot Set Zoom (width={zoom_width:.6f})\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probabil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
